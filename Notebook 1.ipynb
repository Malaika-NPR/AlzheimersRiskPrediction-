{"cells":[{"block_group":"d579db22f840405d971e81b7543a07d2","cell_type":"code","execution_count":null,"metadata":{"deepnote_to_be_reexecuted":true,"cell_id":"d579db22f840405d971e81b7543a07d2","deepnote_block_group":"d579db22f840405d971e81b7543a07d2","deepnote_cell_type":"code","deepnote_sorting_key":"0","deepnote_source":"# DATA 144 â€” MINING & ANALYTICS MIDTERM CHEAT SHEET\n*(Compact reference for Weeks 1â€“7 + Quizzes 1â€“6)*  \nUse 2-column layout in Google Docs â†’ narrow margins â†’ 9-pt font.\n\n---\n\n## ğŸ§© WEEK 1 â€“ DATA PRE-PROCESSING & FEATURE REPRESENTATION\n### Core Ideas\n- **Local vs Strategic Optimization:**  \n  â€¢ Local = hyper-param tuning / ensembling.  \n  â€¢ Strategic = what decision does model support? Would simple stats work? (Ex: engagement vs network growth)\n- **Feature Engineering:** Represent each feature numerically and meaningfully.\n\n### Good Representations\n| Type | Good | Avoid | Notes |\n|:--|:--|:--|:--|\n| Nominal (e.g. Color) | One-Hot Encoding | Alphanumeric ordering | No false order |\n| Ordinal (e.g. Size) | Ranked ints | One-hot if true order exists | Preserve order |\n| Numeric | Keep numeric, normalize | â€” | Avoid scale dominance |\n\n**Z-Score Normalization:**  z = (x â€“ Î¼)/Ïƒ  \n\n### Feature Transformation Example\nCity | State | Date | Temp â†’ State = (lat, lon), Month = 12 one-hots, Temp = numeric. **â†’ 15 columns.**\n\n### Stakeholder Frame\nSpotify uses genre + lyrics + sales to predict song popularity â†’ playlist placement â†’ â†‘ engagement.\n\n#### ğŸ§  Quiz 1 Highlights\n- **Q1:** Least effective way to represent color = *ordinal rank by alphabet*.  \n- **Q2:** Transformed dataset columns = **15**.  \n- **Q3:** Stakeholder example â†’ Spotify predicts popular songs â†’ recommendations.\n\n---\n\n## ğŸ’  WEEK 2 â€“ CLUSTERING ( K-MEANS )\n### Concepts\n- **Clustering vs Classification:** no labels vs labeled learning.  \n- Dataset D in â„áµˆ partitioned into K clusters Câ‚â€¦Câ‚– to minimize within-cluster distance.\n\n**K-Means Steps:** 1) init centroids â†’ 2) assign points â†’ 3) update means â†’ 4) repeat until stable.  \n[[Diagram: K-Means Loop]]\n\n### SSE (Sum of Squared Errors)\nSSE = Î£â‚– Î£â‚“âˆˆCâ‚– â€–x â€“ Î¼â‚–â€–Â²  \n â€¢ Lower SSE = tighter clusters.   \n â€¢ SSE â†“ as K â†‘ (always â†’ 0 when K = n).  \n â€¢ Use **Elbow Method** to pick K.\n\n### Silhouette Coefficient\ns(i) = (b â€“ a)/max(a,b)  \n a = mean dist to same cluster, b = mean dist to nearest cluster.  \n Range [ â€“1, 1 ]; s=0 â†’ equidistant â†’ on border.\n\n### Choosing K\n- Plot SSE vs K â†’ find â€œelbow.â€  \n- Use avg silhouette score (max = best fit).  \n- Normalize features before distance.\n\n| Concept | Formula | Note |\n|:--|:--|:--|\n| Euclidean | âˆšÎ£(xâ‚‚â€“xâ‚)Â² | Distance metric |\n| SSE | Î£â€–xâ€“Î¼â€–Â² | Tightness |\n| Silhouette | (bâ€“a)/max | Quality metric |\n| Assignments | Kâ¿ | Combinatorial count |\n\n#### ğŸ§  Quiz 2 Highlights\n- **Q1:** Use SSE to choose K via Elbow Method + compare runs (diff centroids).  \n- **Q2:** Silhouette range = **[ â€“1, 1 ]**.  \n- **Q3:** s=0 â†’ equal distances to own and nearest cluster.  \n- **Q4:** Assignments = Kâ¿.\n\n[[Diagram: Elbow Method]]\n\n---\n\n## ğŸŒ³ WEEK 3 â€“ DECISION TREES (C4.5 / CART)\n### Terminology\nImpurity = uncertainty of class labels.  \n**Entropy:** H(D)= â€“Î£ páµ¢ logâ‚‚ páµ¢  \n**Gini:** 1â€“Î£ páµ¢Â²  \nC4.5 uses Entropy; CART uses Gini; both greedy & non-parametric.\n\n### Splitting Criterion\nÎ” Impurity = Impurity(D) â€“ Î£ (|Dáµ¥|/|D|) Impurity(Dáµ¥).  \nChoose split with max Î”.  \nStop when pure / no attrs / depth limit.\n\n### Pruning\nPre-prune: limit depth / min leaf.  \nPost-prune: cost-complexity trade-off to reduce overfit.\n\n#### Example (Quiz 3)\n6 high (0.6) + 4 low (0.4) â†’ Gini = 1 â€“ (0.6Â²+0.4Â²)= 0.48.  \nEqual split â†’ 0.5 (max impurity).  \n\n#### ğŸ§  Quiz 3 Highlights\n- **Q1:** Starting Gini = 0.48.  \n- **Q2:** If equal classes â†’ Gini = 0.5.  \n- **Q3:** Best split = attribute & point that maximizes Î” Gini / Info Gain.  \n- **Q4 (Extra Credit):** â€œGiven enough depth, tree classifies perfectly.â€ âœ… True (but overfits).\n\n[[Diagram: Decision Tree Split]]\n\n---\n\n## ğŸ§  WEEK 4 â€“ NEURAL NETWORKS\n### Structure\nFeed-forward NN: input â†’ hidden â†’ output (no loops).  \nz = WÂ·x + b; a = f(z).  \nBackprop = iterative weight updates via âˆ‚loss/âˆ‚W.\n\n### Activations\n| Function | Formula | Range | Purpose |\n|:--|:--|:--|:--|\n| Sigmoid | 1/(1+eâ»Ë£) | (0,1) | Binary output |\n| ReLU | max(0,x) | [0,âˆ) | Hidden layers |\n| Softmax | eá¶»áµ¢/Î£eá¶»â±¼ | (0,1) | Multi-class |\n\n### Training Terms\n- Epoch = full pass through data.  \n- Batch size = # samples per update.  \n- Stop when loss plateaus / max epochs.  \n- Hardware: GPU/TPU acceleration.  \n\n### Example (Q4)\nInput = 1024 features, Hidden = 10, Output = 3  \nWeights = (1024Ã—10)+(10Ã—3)= 10 270 (ignore bias).  \n\n#### ğŸ§  Quiz 4 Highlights\n- **Q1:** Total weights = 10 270.  \n- **Q2:** Sigmoid highest uncertainty = **0.5** (output).  \n- **Q3:** Input that yields 0.5 = **0**.\n\n[[Diagram: Feed-Forward NN]]\n\n---\n\n## ğŸ“Š WEEK 5 â€“ ERROR METRICS & CROSS-VALIDATION\n### Confusion Matrix\n|   | Pred + | Pred â€“ |\n|:--|:--|:--|\n| Actual + | TP | FN |\n| Actual â€“ | FP | TN |\n\n### Classification Metrics\n| Metric | Formula | Meaning |\n|:--|:--|:--|\n| Accuracy | (TP+TN)/(TP+TN+FP+FN) | Overall correctness |\n| Precision | TP/(TP+FP) | Pos pred quality |\n| Recall | TP/(TP+FN) | Coverage of actual pos |\n| F1 | 2PR/(P+R) | Balance P/R |\n| AUC | P(score_pos>score_neg) | Probabilistic ranking |\n\n**Example (Quiz 5 Q1):** TP=2, FP=1 â†’ Precision = 2/3 = 0.67.  \n**AUC Usage:** only for probabilistic binary predictions.\n\n### Regression Metrics\n| Metric | Formula | Notes |\n|:--|:--|:--|\n| MAE | Î£|yâ€“Å·|/n | Linear error |\n| RMSE | âˆšÎ£(yâ€“Å·)Â²/n | Penalizes outliers |\n| RÂ² | 1â€“SSE/SST | Variance explained |\n\n### Cross-Validation (k-Fold)\n1. Split data into k folds.  \n2. Train on k-1, test on 1.  \n3. Repeat k times, avg metric.  \nTypes: k-fold, leave-1-out, stratified.  \nAlways use same folds for fair comparison.\n\n#### ğŸ§  Quiz 5 Highlights\n- **Q1:** Precision = 0.67.  \n- **Q2:** AUC â†’ probabilistic binary pred only.\n\n[[Diagram: ROC Curve]]\n\n---\n\n## ğŸ§¬ WEEK 6 â€“ ENSEMBLE LEARNING\nGoal: combine diverse models to reduce variance or bias.\n\n### Simple Combination (Aggregation)\n- Averages predictions (regression) or majority vote (classification).  \n- No bootstrapping / weights. Can mix algorithms.  \n- **Differs from Bagging:** no resampling, no same-model requirement.\n\n### Bagging (Bootstrap Aggregation)\n- Bootstrap sample â†’ train same model â†’ aggregate.  \n- Reduces variance; handles noise. Parallelizable.  \n- Example: **Random Forest** (bootstrapped rows + random feature subsets).  \n Hyper-params: #trees, max depth, min leaf, feat ratio.\n\n### Boosting\n- Sequential; each model focuses on errors of prev.  \n- Weights â†‘ for misclassified points.  \n- Final = weighted vote. Reduces bias. Not parallelizable.  \n- Ex: AdaBoost, Gradient Boost.\n\n### Stacking / Blending\n- Train base models â†’ feed preds to meta-model.  \n- Stacking = CV; Blending = hold-out val.  \n- Improves generalization across diverse learners.\n\n| Method | Bootstrap | Sequential | Parallel | Combiner | Goal |\n|:--|:--|:--|:--|:--|:--|\n| Simple Agg | âŒ | âŒ | âœ… | Mean/Vote | Baseline |\n| Bagging | âœ… | âŒ | âœ… | Mean/Vote | â†“Variance |\n| Boosting | âœ…(Weighted) | âœ… | âŒ | Weighted Vote | â†“Bias |\n| Stacking | âŒ | Partial | âš™ | Meta-Model | Generalize |\n\n#### ğŸ§  Quiz 6 Highlights\n- **Q1:** Simple Aggregation differs from Bagging â†’ no bootstrapping + can mix models.  \n- **Q2:** Weighted bootstrap based on error â†’ **Boosting**.  \n- **Q3:** Not parallelizable â†’ **Boosting**.\n\n[[Diagram: Ensemble Flow]]\n"},"outputs":[],"source":"# DATA 144 â€” MINING & ANALYTICS MIDTERM CHEAT SHEET\n*(Compact reference for Weeks 1â€“7 + Quizzes 1â€“6)*  \nUse 2-column layout in Google Docs â†’ narrow margins â†’ 9-pt font.\n\n---\n\n## ğŸ§© WEEK 1 â€“ DATA PRE-PROCESSING & FEATURE REPRESENTATION\n### Core Ideas\n- **Local vs Strategic Optimization:**  \n  â€¢ Local = hyper-param tuning / ensembling.  \n  â€¢ Strategic = what decision does model support? Would simple stats work? (Ex: engagement vs network growth)\n- **Feature Engineering:** Represent each feature numerically and meaningfully.\n\n### Good Representations\n| Type | Good | Avoid | Notes |\n|:--|:--|:--|:--|\n| Nominal (e.g. Color) | One-Hot Encoding | Alphanumeric ordering | No false order |\n| Ordinal (e.g. Size) | Ranked ints | One-hot if true order exists | Preserve order |\n| Numeric | Keep numeric, normalize | â€” | Avoid scale dominance |\n\n**Z-Score Normalization:**  z = (x â€“ Î¼)/Ïƒ  \n\n### Feature Transformation Example\nCity | State | Date | Temp â†’ State = (lat, lon), Month = 12 one-hots, Temp = numeric. **â†’ 15 columns.**\n\n### Stakeholder Frame\nSpotify uses genre + lyrics + sales to predict song popularity â†’ playlist placement â†’ â†‘ engagement.\n\n#### ğŸ§  Quiz 1 Highlights\n- **Q1:** Least effective way to represent color = *ordinal rank by alphabet*.  \n- **Q2:** Transformed dataset columns = **15**.  \n- **Q3:** Stakeholder example â†’ Spotify predicts popular songs â†’ recommendations.\n\n---\n\n## ğŸ’  WEEK 2 â€“ CLUSTERING ( K-MEANS )\n### Concepts\n- **Clustering vs Classification:** no labels vs labeled learning.  \n- Dataset D in â„áµˆ partitioned into K clusters Câ‚â€¦Câ‚– to minimize within-cluster distance.\n\n**K-Means Steps:** 1) init centroids â†’ 2) assign points â†’ 3) update means â†’ 4) repeat until stable.  \n[[Diagram: K-Means Loop]]\n\n### SSE (Sum of Squared Errors)\nSSE = Î£â‚– Î£â‚“âˆˆCâ‚– â€–x â€“ Î¼â‚–â€–Â²  \n â€¢ Lower SSE = tighter clusters.   \n â€¢ SSE â†“ as K â†‘ (always â†’ 0 when K = n).  \n â€¢ Use **Elbow Method** to pick K.\n\n### Silhouette Coefficient\ns(i) = (b â€“ a)/max(a,b)  \n a = mean dist to same cluster, b = mean dist to nearest cluster.  \n Range [ â€“1, 1 ]; s=0 â†’ equidistant â†’ on border.\n\n### Choosing K\n- Plot SSE vs K â†’ find â€œelbow.â€  \n- Use avg silhouette score (max = best fit).  \n- Normalize features before distance.\n\n| Concept | Formula | Note |\n|:--|:--|:--|\n| Euclidean | âˆšÎ£(xâ‚‚â€“xâ‚)Â² | Distance metric |\n| SSE | Î£â€–xâ€“Î¼â€–Â² | Tightness |\n| Silhouette | (bâ€“a)/max | Quality metric |\n| Assignments | Kâ¿ | Combinatorial count |\n\n#### ğŸ§  Quiz 2 Highlights\n- **Q1:** Use SSE to choose K via Elbow Method + compare runs (diff centroids).  \n- **Q2:** Silhouette range = **[ â€“1, 1 ]**.  \n- **Q3:** s=0 â†’ equal distances to own and nearest cluster.  \n- **Q4:** Assignments = Kâ¿.\n\n[[Diagram: Elbow Method]]\n\n---\n\n## ğŸŒ³ WEEK 3 â€“ DECISION TREES (C4.5 / CART)\n### Terminology\nImpurity = uncertainty of class labels.  \n**Entropy:** H(D)= â€“Î£ páµ¢ logâ‚‚ páµ¢  \n**Gini:** 1â€“Î£ páµ¢Â²  \nC4.5 uses Entropy; CART uses Gini; both greedy & non-parametric.\n\n### Splitting Criterion\nÎ” Impurity = Impurity(D) â€“ Î£ (|Dáµ¥|/|D|) Impurity(Dáµ¥).  \nChoose split with max Î”.  \nStop when pure / no attrs / depth limit.\n\n### Pruning\nPre-prune: limit depth / min leaf.  \nPost-prune: cost-complexity trade-off to reduce overfit.\n\n#### Example (Quiz 3)\n6 high (0.6) + 4 low (0.4) â†’ Gini = 1 â€“ (0.6Â²+0.4Â²)= 0.48.  \nEqual split â†’ 0.5 (max impurity).  \n\n#### ğŸ§  Quiz 3 Highlights\n- **Q1:** Starting Gini = 0.48.  \n- **Q2:** If equal classes â†’ Gini = 0.5.  \n- **Q3:** Best split = attribute & point that maximizes Î” Gini / Info Gain.  \n- **Q4 (Extra Credit):** â€œGiven enough depth, tree classifies perfectly.â€ âœ… True (but overfits).\n\n[[Diagram: Decision Tree Split]]\n\n---\n\n## ğŸ§  WEEK 4 â€“ NEURAL NETWORKS\n### Structure\nFeed-forward NN: input â†’ hidden â†’ output (no loops).  \nz = WÂ·x + b; a = f(z).  \nBackprop = iterative weight updates via âˆ‚loss/âˆ‚W.\n\n### Activations\n| Function | Formula | Range | Purpose |\n|:--|:--|:--|:--|\n| Sigmoid | 1/(1+eâ»Ë£) | (0,1) | Binary output |\n| ReLU | max(0,x) | [0,âˆ) | Hidden layers |\n| Softmax | eá¶»áµ¢/Î£eá¶»â±¼ | (0,1) | Multi-class |\n\n### Training Terms\n- Epoch = full pass through data.  \n- Batch size = # samples per update.  \n- Stop when loss plateaus / max epochs.  \n- Hardware: GPU/TPU acceleration.  \n\n### Example (Q4)\nInput = 1024 features, Hidden = 10, Output = 3  \nWeights = (1024Ã—10)+(10Ã—3)= 10 270 (ignore bias).  \n\n#### ğŸ§  Quiz 4 Highlights\n- **Q1:** Total weights = 10 270.  \n- **Q2:** Sigmoid highest uncertainty = **0.5** (output).  \n- **Q3:** Input that yields 0.5 = **0**.\n\n[[Diagram: Feed-Forward NN]]\n\n---\n\n## ğŸ“Š WEEK 5 â€“ ERROR METRICS & CROSS-VALIDATION\n### Confusion Matrix\n|   | Pred + | Pred â€“ |\n|:--|:--|:--|\n| Actual + | TP | FN |\n| Actual â€“ | FP | TN |\n\n### Classification Metrics\n| Metric | Formula | Meaning |\n|:--|:--|:--|\n| Accuracy | (TP+TN)/(TP+TN+FP+FN) | Overall correctness |\n| Precision | TP/(TP+FP) | Pos pred quality |\n| Recall | TP/(TP+FN) | Coverage of actual pos |\n| F1 | 2PR/(P+R) | Balance P/R |\n| AUC | P(score_pos>score_neg) | Probabilistic ranking |\n\n**Example (Quiz 5 Q1):** TP=2, FP=1 â†’ Precision = 2/3 = 0.67.  \n**AUC Usage:** only for probabilistic binary predictions.\n\n### Regression Metrics\n| Metric | Formula | Notes |\n|:--|:--|:--|\n| MAE | Î£|yâ€“Å·|/n | Linear error |\n| RMSE | âˆšÎ£(yâ€“Å·)Â²/n | Penalizes outliers |\n| RÂ² | 1â€“SSE/SST | Variance explained |\n\n### Cross-Validation (k-Fold)\n1. Split data into k folds.  \n2. Train on k-1, test on 1.  \n3. Repeat k times, avg metric.  \nTypes: k-fold, leave-1-out, stratified.  \nAlways use same folds for fair comparison.\n\n#### ğŸ§  Quiz 5 Highlights\n- **Q1:** Precision = 0.67.  \n- **Q2:** AUC â†’ probabilistic binary pred only.\n\n[[Diagram: ROC Curve]]\n\n---\n\n## ğŸ§¬ WEEK 6 â€“ ENSEMBLE LEARNING\nGoal: combine diverse models to reduce variance or bias.\n\n### Simple Combination (Aggregation)\n- Averages predictions (regression) or majority vote (classification).  \n- No bootstrapping / weights. Can mix algorithms.  \n- **Differs from Bagging:** no resampling, no same-model requirement.\n\n### Bagging (Bootstrap Aggregation)\n- Bootstrap sample â†’ train same model â†’ aggregate.  \n- Reduces variance; handles noise. Parallelizable.  \n- Example: **Random Forest** (bootstrapped rows + random feature subsets).  \n Hyper-params: #trees, max depth, min leaf, feat ratio.\n\n### Boosting\n- Sequential; each model focuses on errors of prev.  \n- Weights â†‘ for misclassified points.  \n- Final = weighted vote. Reduces bias. Not parallelizable.  \n- Ex: AdaBoost, Gradient Boost.\n\n### Stacking / Blending\n- Train base models â†’ feed preds to meta-model.  \n- Stacking = CV; Blending = hold-out val.  \n- Improves generalization across diverse learners.\n\n| Method | Bootstrap | Sequential | Parallel | Combiner | Goal |\n|:--|:--|:--|:--|:--|:--|\n| Simple Agg | âŒ | âŒ | âœ… | Mean/Vote | Baseline |\n| Bagging | âœ… | âŒ | âœ… | Mean/Vote | â†“Variance |\n| Boosting | âœ…(Weighted) | âœ… | âŒ | Weighted Vote | â†“Bias |\n| Stacking | âŒ | Partial | âš™ | Meta-Model | Generalize |\n\n#### ğŸ§  Quiz 6 Highlights\n- **Q1:** Simple Aggregation differs from Bagging â†’ no bootstrapping + can mix models.  \n- **Q2:** Weighted bootstrap based on error â†’ **Boosting**.  \n- **Q3:** Not parallelizable â†’ **Boosting**.\n\n[[Diagram: Ensemble Flow]]\n"},{"block_group":"4e918614a0a8491c820a3f9f9ceecf4a","cell_type":"code","execution_count":null,"metadata":{"cell_id":"50b04d4d517b465099744f30d8d476be","deepnote_block_group":"4e918614a0a8491c820a3f9f9ceecf4a","deepnote_cell_type":"code","deepnote_sorting_key":"1","deepnote_source":""},"outputs":[],"source":""}],
        "metadata": {"deepnote_notebook_id":"03fb3dd3f9464b2993af82b134c484e8"},
        "nbformat": "4",
        "nbformat_minor": "0",
        "version": "0"
      }